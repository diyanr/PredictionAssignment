---
title: "Practical Machine Learning Course Project"
author: "Diyan Rahaman"
date: "August 19, 2016"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```
## BACKGROUND
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

## DATA PRE-PROCESSING

+ Import libraries:
```{r}
library(caret)
set.seed(1001)
```

+ Download the data:
```{r}
trainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainData <- read.csv(trainUrl, na.strings=c("NA","#DIV/0!",""))
testData <- read.csv(testUrl, na.strings=c("NA","#DIV/0!",""))
dim(trainData)
dim(testData)
```

+ Remove near zero values
```{r}
NZV <- nearZeroVar(trainData)
trainData <- trainData[, -NZV]
dim(trainData)
```

+ Remove variables that are mostly NA:
```{r}
allNA    <- sapply(trainData, function(x) mean(is.na(x))) > 0.75
trainData <- trainData[, allNA==FALSE]
dim(trainData)
```

+ Remove the identifying variables:
```{r}
trainData <- trainData[, -seq(1,6)]
dim(trainData)
```

+ Partition the training data into a training set and a test set:
```{r}
inTrain  <- createDataPartition(trainData$classe, p=0.7, list=FALSE)
trainSet <- trainData[inTrain, ]
testSet  <- trainData[-inTrain, ]
dim(trainSet)
dim(testSet)
```

## CREATE MODELS

In this section we will create different models using the Caret package and look at the accuracy of each type of model.

We will do 10-fold cross-validation on the training set with which to train each model.
```{r}
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10, 
                     repeats = 3)
```

### Linear Discriminant Analysis

+ Create a lda model
```{r}
lda.fit <- train(classe ~ ., 
                 data = trainSet, 
                 method = "lda", 
                 trControl = ctrl)
lda.fit
```

+ Use the best fitting model to run predictions on the test set and look at the accuracy of the predictions using a confusion matrix:
```{r}
lda.pred <- predict(lda.fit, testSet)
confusionMatrix(lda.pred, testSet$classe)
```

### Random Forest

+ Create a rf model
```{r}
rf.fit <- train(classe ~ ., 
                 data = trainSet, 
                 method = "rf", 
                 trControl = ctrl)
rf.fit
```

+ Use the best fitting model to run predictions on the test set and look at the accuracy of the predictions using a confusion matrix:
```{r}
rf.pred <- predict(rf.fit, testSet)
confusionMatrix(rf.pred, testSet$classe)
```

### Gradient Boosting Machine

+ Create a gbm model:
```{r}
gbm.fit <- train(classe ~ ., 
                 data = trainSet, 
                 method = "gbm", 
                 trControl = ctrl, 
                 verbose = FALSE)
gbm.fit
```

+ Use the best fitting model to run predictions on the test set and look at the accuracy of the predictions using a confusion matrix:
```{r}
gbm.pred <- predict(gbm.fit, testSet)
confusionMatrix(gbm.pred, testSet$classe)
```

## RUN THE BEST MODEL ON THE TEST DATA

Based on the accuracy of the best model rf, we predict the test data:
```{r}
predict(rf.fit, testData)
```
